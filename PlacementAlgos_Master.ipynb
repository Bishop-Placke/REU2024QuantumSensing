{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-05T22:13:13.955812Z",
     "start_time": "2024-08-05T22:13:12.561661Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import scipy as sp\n",
    "#from scipy.special import jn\n",
    "#import jcamp as jc\n",
    "import itertools\n",
    "import math\n",
    "import hdbscan\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import warnings"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T22:13:13.971467Z",
     "start_time": "2024-08-05T22:13:13.957825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''Noisy IR Spectra Generation Methods'''\n",
    "\n",
    "#Generate the Data. CALL THIS!\n",
    "def getNoisyIRSpectra(cleanIR, number_of_trials_per_molecule=100, x_axis_resolution=20000, machine_noise=False, original_gaussian_noise=0.2, max_speed_exponent=7, val_machine_noise=0.05):\n",
    "    noise_ranges=[original_gaussian_noise, x_axis_resolution/1000, 3*(10 ** max_speed_exponent), val_machine_noise]\n",
    "    if(machine_noise):\n",
    "        IR_data_1 = cleanIR#reaxis_multiple_IR(load_all_npy_data(number_of_molecules),x_axis_resolution)\n",
    "        IR_data_2 = []\n",
    "        IR_data_2.append(IR_data_1[0])\n",
    "        for index in range(len(IR_data_1)-1):\n",
    "            for index2 in range(number_of_trials_per_molecule):\n",
    "                IR_data_2.append( vertical_noise_addition(gaussian_smoothing(vertical_noise_addition(R_B_shift_data(IR_data_1[index+1],IR_data_1[0],np.random.random()*noise_ranges[2],np.random.random()*2*np.pi),np.random.random()*noise_ranges[0]),noise_ranges[1]),np.random.random()*noise_ranges[3]))\n",
    "    if(not machine_noise):\n",
    "        IR_data_1 = cleanIR#reaxis_multiple_IR(convert_all_data(load_all_jc_data(number_of_molecules)),x_axis_resolution)\n",
    "        IR_data_2 = []\n",
    "        IR_data_2.append(IR_data_1[0])\n",
    "        for index in range(len(IR_data_1)-1):\n",
    "            for index2 in range(number_of_trials_per_molecule):\n",
    "                IR_data_2.append( gaussian_smoothing(vertical_noise_addition(R_B_shift_data(IR_data_1[index+1],IR_data_1[0],np.random.random()*noise_ranges[2],np.random.random()*2*np.pi),np.random.random()*noise_ranges[0]),noise_ranges[1]))\n",
    "    return IR_data_2\n",
    "\n",
    "#Methods for linear interpolation, gaussian smoothing, (vertical) gaussian noise addition, and R/B shift\n",
    "def interpolate_data_to_new_axis(data,originalAxis,newAxis, style = 2):\n",
    "     # this method converts points in data from originalAxis to what their values would be at newAxis by interpoliation,\n",
    "     # style determines how to fill in the points that are beyond the range of originalAxis, 0 fills them in with 0s, 1 fills them in with 1's, 2 filles them in with the last data point\n",
    "     # any other value fills them in by interpolating the last point via the slope from the second to last point\n",
    "    newData = np.zeros(newAxis.size, dtype=type(data[0]))\n",
    "    counter = 0\n",
    "    for i in range(newAxis.size):\n",
    "        if newAxis[i]<originalAxis[0]:\n",
    "            if( style==0):newData[i]=0\n",
    "            elif(style==1):newData[i]=1\n",
    "            elif(style==2):newData[i]=data[0]\n",
    "            else: newData[i]=data[0]+(newAxis[i]-originalAxis[0])*(data[1]-data[0])/(originalAxis[1]-originalAxis[0])\n",
    "        elif newAxis[i]>originalAxis[-1]:\n",
    "            if( style==0):newData[i]=0\n",
    "            elif(style==1):newData[i]=1\n",
    "            elif(style==2):newData[i]=data[-1]\n",
    "            else: newData[i]=data[-1]+(newAxis[i]-originalAxis[-1])*(data[-2]-data[-1])/(originalAxis[-2]-originalAxis[-1])\n",
    "        elif newAxis[i]==originalAxis[counter]:\n",
    "            newData[i] = data[counter]\n",
    "        else:\n",
    "            while originalAxis[counter]<newAxis[i]:\n",
    "                counter+=1\n",
    "            newData[i]=data[counter-1]+(newAxis[i]-originalAxis[counter-1])*(data[counter]-data[counter-1])/(originalAxis[counter]-originalAxis[counter-1])\n",
    "    return(newData)\n",
    "\n",
    "def R_B_shift( axis1, vel,ang): #This method gives a red/blue shifted axis (using wave numbers, and returns it in wave numbers), takes in velocity in m/s and angle in rad\n",
    "    c=3e8\n",
    "    zp1 = (1+vel*np.cos(ang)/c)/np.sqrt(1-vel*vel/(c*c))\n",
    "    axis2=axis1/zp1\n",
    "    return(axis2)\n",
    "\n",
    "def R_B_shift_data(data, axis1, vel,ang):\n",
    "    return(interpolate_data_to_new_axis(data,axis1,R_B_shift(axis1,vel,ang)))\n",
    "\n",
    "def gaussian_smoothing(spectrum, noise_param): #this does gaussian smoothing\n",
    "    #It takes in the spectrum and smooths according to the noise param, which is units of array\n",
    "\n",
    "    shiftFactor=int(spectrum.size/2) #this is  the center of the array\n",
    "\n",
    "    runningVect=np.zeros(spectrum.size) #this will be the output vector\n",
    "\n",
    "    vect = np.array([np.exp(-(j-spectrum.size/2)*(j-spectrum.size/2)/(2*noise_param*noise_param))/np.sqrt(2*np.pi*noise_param*noise_param) for j in range(spectrum.size)])\n",
    "    #^this sets up a gaussian distribution around the center of the array.\n",
    "\n",
    "    for i in range(int(spectrum.size/2)):\n",
    "        runningVect+=np.concatenate((vect[i:],vect[:i]),axis=0)*spectrum[shiftFactor-i]\n",
    "    for i in range(int(spectrum.size/2)):\n",
    "        runningVect+=np.concatenate((vect[-(i+1):],vect[:-(i+1)]),axis=0)*spectrum[shiftFactor+(i)]\n",
    "    return(runningVect)\n",
    "\n",
    "def vertical_noise_addition(spec,noise): #this adds vertical noise to the spectrum the noise is added as a gaussian centred at 0 with \n",
    "    #height given by 'noise', so 'noise' should be in the same units (and relative scale) as spectrum\n",
    "    return(spec+np.random.normal(0,noise,spec.size))\n"
   ],
   "id": "420f50fff44dac21",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T22:13:13.981113Z",
     "start_time": "2024-08-05T22:13:13.973477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''Variance Calculation Methods'''\n",
    "\n",
    "#Build arrays of Combinations of IR Spectra. CALL THIS FIRST, THEN THE NEXT ONE!\n",
    "def buildChooseKIRSpectraArrays(file, k):\n",
    "    full_array = file[0]\n",
    "    '''Combinations are the combos of numMolecules choose k''' \n",
    "    for combination in itertools.combinations(range(1, len(file)), k):\n",
    "        blockToAdd = file[combination[0]] #Peel off first one so concatenate works\n",
    "        for element in combination[1:]:\n",
    "            blockToAdd = np.vstack((blockToAdd, file[element]))\n",
    "        full_array = np.vstack((full_array, blockToAdd))\n",
    "    return full_array\n",
    "\n",
    "#Row 0 will be Frequencies/Wave Numbers. CALL THIS SECOND!\n",
    "def buildVarArray(combinedData, molCount, k):\n",
    "    varArray = combinedData[0]\n",
    "    numberOfCombinations = molChooseK(molCount, k)\n",
    "    #print('To begin, the SD array has shape:', sdArray.shape, 'And its entries are:', sdArray)\n",
    "    for i in range(1, numberOfCombinations + 1):\n",
    "        varArray = np.vstack((varArray, find_variance(selectCombination(combinedData, k, i))))\n",
    "    #print('Line 1 of sdArray was giving the original IR Spectra and not the SDs of any combinations. Here is what line 1 reads', sdArray[1])\n",
    "    return varArray\n",
    "\n",
    "def find_variance(IRSpectra):\n",
    "    \"\"\"\n",
    "    Calculate the variance of IR spectra across samples.\n",
    "    param: IRSpectra: (p, q) LEAVE OUT THE FREQUENCY ROW\n",
    "    Returns:\n",
    "    variance: (q,)\n",
    "    \"\"\"\n",
    "    return np.var(IRSpectra, axis=0)\n",
    "\n",
    "def selectCombination(combinedData, k, combination):\n",
    "    rowIndexToStart = 1+(combination-1)*k\n",
    "    selectedCombination = []\n",
    "    for row in range(rowIndexToStart, rowIndexToStart + k):\n",
    "        selectedCombination.append(combinedData[row])\n",
    "    return selectedCombination\n",
    "\n",
    "def molChooseK(molCount, k):\n",
    "    return int(math.factorial(int(molCount))/(math.factorial(int(k))*math.factorial(int(molCount-k))))\n"
   ],
   "id": "e59a7e87b7547322",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T22:13:13.994131Z",
     "start_time": "2024-08-05T22:13:13.983128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''Comb Placement Methods'''\n",
    "'''\n",
    "    Chooses a comb according the following algorithm:\n",
    "        Consider a (1+(NumMolecules choose SubsetSize))x(NumWaveNumbers) array\n",
    "        First, place a comb according to the integration method for some arbitrary combination\n",
    "        (say, the first combination).\n",
    "        Then, for each comb yet to be placed:\n",
    "            Sum across the standard deviations of each combination at the already placed combs.\n",
    "            For whichever combination had the lowest sum,\n",
    "                place a comb according to the integral method, using that combination's standard deviations.\n",
    "    You will provide:\n",
    "    Standard Deviation Array of Combinations of Molecules (will work for all molecules at once)\n",
    "    Number of Combs to place\n",
    "    Width of a comb (in wave numbers, typically 10-20)'''\n",
    "#Returns array of Left Handed Starts. CALL THIS!\n",
    "def wave_numbers_for_combination_variance(combination_array, numCombs, combWidth):\n",
    "    '''\n",
    "    Pass in an array of pairwise standard deviations, WAVE NUMBERS ARE FIRST ROW!!!\n",
    "    Returns starting indices for combs\n",
    "    :param combination_array: Array of standard deviations for combinations of molecules WITH WAVE NUMBERS\n",
    "    :param numCombs: Number of combs to place\n",
    "    :param combWidth: Width of each comb in WAVE NUMBERS\n",
    "    :return: Array of left-handed starts\n",
    "    '''\n",
    "    #Place the first comb\n",
    "    indices = integrateRow(combination_array[1], combWidth=combWidth)\n",
    "    combosCalled = [1]\n",
    "    #print('Start indices begin as:', indices)\n",
    "    for i in range(numCombs-1):\n",
    "        indexOfLowestPair = determineLowestCombination(findVarianceObservedInEachCombination(combination_array, indices, combWidth))\n",
    "        combosCalled = np.append(combosCalled, indexOfLowestPair)\n",
    "        indices = np.concatenate((indices, integrateRow(updateDeviations(combination_array[indexOfLowestPair], indices, combWidth), combWidth)))\n",
    "    #print('The pairs were called in this order:', combosCalled)\n",
    "    return shiftIndices(indices, combination_array[0][0])\n",
    "\n",
    "def findVarianceObservedInEachCombination(combination_array, startIndices, combWidth, callingOnlyOnce=False):\n",
    "    '''\n",
    "    Sum the variance of each combination of molecules, according to\n",
    "    whether a comb has been placed at each wave number\n",
    "    :param combination_array: Full combination array\n",
    "    :param startIndices: Set of comb starting wave numbers\n",
    "    :param combWidth: Width of a comb\n",
    "    :param callingOnlyOnce: Set to true if you want to know how much \n",
    "                            variance was observed by each comb\n",
    "    :return: array of total variance observed by placed combs for each combination\n",
    "            Index n is combination n+1\n",
    "    '''\n",
    "    #combsPlaced = len(startIndices)\n",
    "    comboNumber = 0\n",
    "    totalVariancesOfPairs = np.zeros(shape=(len(combination_array)-1))\n",
    "    for combination in combination_array[1:]:\n",
    "        totalVariance = 0\n",
    "        for start in startIndices:\n",
    "            totalVariance += np.sum(combination[int(start):int(start)+combWidth])\n",
    "        totalVariancesOfPairs[comboNumber] = totalVariance\n",
    "        comboNumber += 1\n",
    "        if callingOnlyOnce == True:\n",
    "            print('Combination', comboNumber, 'has total variance:', totalVariance)\n",
    "    return totalVariancesOfPairs\n",
    "\n",
    "def determineLowestCombination(observedVariances):\n",
    "    '''\n",
    "    Finds which molecule combination has seen the lowest observed variance\n",
    "    :param observedVariances: array of total variance observed by placed combs for each combination\n",
    "    :return: Returns the lowest combination's index with respect to \n",
    "            the original, full combination array (accounts for row of wave numbers)\n",
    "    '''\n",
    "    #Adding 1 is necessary due to wave number row\n",
    "    return np.argmin(observedVariances) + 1\n",
    "\n",
    "def updateDeviations(combination, startIndices, combWidth):\n",
    "    '''\n",
    "    Sets variances at wave numbers which already are taken up by a comb\n",
    "    to 0 so that they are not considered in the next iteration of the\n",
    "    integral optimization method\n",
    "    :param combination: The single row of standard deviations corresponding to\n",
    "                        the combination being integrated\n",
    "    :param startIndices: Set of comb starting wave numbers\n",
    "    :param combWidth: Width of a comb\n",
    "    :return: Sparse row of standard deviations for a single combination\n",
    "    '''\n",
    "    for index in startIndices:\n",
    "        combination[index: index + combWidth] = 0\n",
    "    return combination\n",
    "\n",
    "def integrateRow(combination, combWidth, combsToPlace=1):#, waveNumbersToTruncate):\n",
    "    '''\n",
    "    Finds the wave number at which the left hand of a comb should be placed\n",
    "    to maximize the sum of standard deviations to-be-observed by said comb\n",
    "    :param combination: The single row of standard deviations corresponding to\n",
    "                        the (lowest, according to determineLowestCombination method) \n",
    "                        combination being integrated\n",
    "    :param combWidth: (͡°͜ʖ͡°)\n",
    "    :param combsToPlace: Determines the number times to iterate\n",
    "                        through integration. Just leave as 1.\n",
    "    :return: An array of the left handed indices which maximize the integral\n",
    "            of standard deviations, for the given combination, over a comb width\n",
    "    '''\n",
    "    startIndices = []\n",
    "    for j in range(combsToPlace):\n",
    "        max_sum = np.sum(combination[0:combWidth-1])\n",
    "        current_sum = max_sum\n",
    "        startIndexOfMaximum = 0\n",
    "        #Iterate through all wave numbers to find index of max interval\n",
    "        for i in range(0, len(combination) - combWidth + 1):\n",
    "            current_sum = current_sum - combination[i - 1] + combination[i + combWidth - 1]\n",
    "            if current_sum > max_sum:\n",
    "                max_sum = current_sum\n",
    "                startIndexOfMaximum = i\n",
    "        startIndices.append(startIndexOfMaximum)\n",
    "    return startIndices\n",
    "\n",
    "def shiftIndices(indices, lowestWaveNumber):\n",
    "    '''\n",
    "    Ensure outputted left-hand wave number starts is in \n",
    "    wave numbers rather than Python Array indices\n",
    "    :param indices: The starting indices found by integration methodology\n",
    "    :param lowestWaveNumber: The lowest wave number found in the \"frequency\" row\n",
    "                            from the original standard deviation array\n",
    "    :return: An array of the left handed wave numbers which maximize\n",
    "     the integral of standard deviations\n",
    "    '''\n",
    "    for i in range(len(indices) - 1):\n",
    "        indices[i] += lowestWaveNumber\n",
    "    return indices\n"
   ],
   "id": "be9881c0f7da4394",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T22:13:14.011451Z",
     "start_time": "2024-08-05T22:13:13.997145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''Comb Interaction Methods'''\n",
    "\n",
    "#Returns an array of shape (# of Noisy IR, Width * 10 * combCount) array.CALL THIS!\n",
    "def simulateCombInteraction(width, combCount, waveStarts, noisy_IR_spectra, drift_comb=0.000, jitter_comb=0.000, refractive_index_comb = 000.0, absorption_coefficient_comb = 0.0, total_experiment_duration = 1e1, teeth_spacing = 1):\n",
    "    frequencies = noisy_IR_spectra[0]\n",
    "    grand_x = np.linspace(0, 4000, 40000, endpoint = False)\n",
    "    starts = waveStarts[0:combCount]\n",
    "    export = []\n",
    "    for stance in range(1, noisy_IR_spectra.shape[0]):\n",
    "        input_ir_y_axis = noisy_IR_spectra[stance] #These are the IR values to be multiplied against\n",
    "        transmittance_values = input_ir_y_axis / (np.max(input_ir_y_axis)) # Normalize\n",
    "        grand_y = np.zeros(len(grand_x)) #This is the row that stores intensities\n",
    "        #after the interaction (i.e. it is what's saved)\n",
    "        #For Each Start Index/Each comb\n",
    "        rowToAdd = []\n",
    "        for guide in range(len(starts)):\n",
    "            ### START COMB CREATION\n",
    "            # Main parameters\n",
    "            peak_spacing = teeth_spacing\n",
    "            wavenumber_broadness = 3 * width\n",
    "            horizontal_comb_shift = find_center(starts[guide], width)\n",
    "            noise_of_pulse = 0.00\n",
    "            # Apply parameters\n",
    "            broadness_of_comb = wavenumber_broadness / 100\n",
    "            comb_parameters = {'rep_rate': peak_spacing,\n",
    "                      'pulse_duration': 60e-3 * (1 / broadness_of_comb),\n",
    "                      'time': total_experiment_duration,\n",
    "                      'sample_rate': 100e0 * broadness_of_comb,\n",
    "                      'noise': noise_of_pulse,\n",
    "                      'jitter': jitter_comb,\n",
    "                      'drift': drift_comb,\n",
    "                      'n_0': refractive_index_comb,\n",
    "                      'alpha_0': absorption_coefficient_comb}\n",
    "            # Pass input through comb creation functions defined above\n",
    "            comb_x_axis = comb_x(comb_parameters)\n",
    "            comb_y_axis = comb_y(comb_parameters, comb_x_axis)\n",
    "            final_x_axis = comb_x_axis + horizontal_comb_shift\n",
    "            final_y_axis = comb_y_axis / (np.max(comb_y_axis))\n",
    "            new_values = trim_data(final_x_axis, final_y_axis, find_center(starts[guide], width), width)\n",
    "            # Interpolate IR spectra values and simulate interaction with comb\n",
    "            ir_spectrum_interpolated_values = np.interp(x = new_values[0], xp = frequencies, fp = transmittance_values)\n",
    "            exiting_comb = ir_spectrum_interpolated_values * new_values[1]\n",
    "            sorted_indices = np.argsort(new_values[0])\n",
    "            updated_y = []\n",
    "            for finality in sorted_indices:\n",
    "                #updated_x.append(new_values[0][finality])\n",
    "                updated_y.append(exiting_comb[finality])\n",
    "            rowToAdd = np.concatenate((rowToAdd, updated_y))\n",
    "        export.append(rowToAdd)\n",
    "    return np.asarray(export)\n",
    "\n",
    "# Define comb creation functions\n",
    "def comb_x(cps1):\n",
    "  comb_x_values = np.fft.fftfreq(n = int(cps1['time'] * cps1['sample_rate']), d = 1 / cps1['sample_rate'])\n",
    "  return comb_x_values\n",
    "\n",
    "def calculate_h(cps2, comb_x_values_i):\n",
    "  path_length = 100e-3\n",
    "  speed_of_light = 3e8\n",
    "  refractive_index = cps2['n_0']\n",
    "  absorption_coefficient = cps2['alpha_0']\n",
    "  refractive_index_transformed = refractive_index + 0.1 * np.sin(comb_x_values_i*2*np.pi)\n",
    "  absorption_coeffient_transoformed = absorption_coefficient * np.exp(-comb_x_values_i / 1.5e14)\n",
    "  H_absorption_value = np.exp(-absorption_coeffient_transoformed * path_length)\n",
    "  H_phase_value = np.exp(-1j * 2 * np.pi * comb_x_values_i * (refractive_index_transformed - 1) * path_length / speed_of_light)\n",
    "  H_value = H_absorption_value * H_phase_value\n",
    "  return H_value\n",
    "\n",
    "def comb_y(cps3, comb_x_values_j):\n",
    "  # Identify the basic independent variable points representing the entire wave, known as samples\n",
    "  number_of_samples = int(cps3['time'] * cps3['sample_rate'])\n",
    "  sample_set = np.zeros(number_of_samples) # Unit is 'number of samples,' representing total amount of points present in the grand train\n",
    "\n",
    "  # Addresses pulses in the wave\n",
    "  number_of_pulses_without_reference_to_samples = int(cps3['time'] * cps3['rep_rate'])\n",
    "  amount_of_samples_coincident_with_pulses = int(cps3['pulse_duration'] * cps3['sample_rate']) # in just one pulse\n",
    "\n",
    "  # Identify the time points (with units of seconds, not to be confused with sample points) at which pulses start\n",
    "  pulse_drift_black_box = np.linspace(0,\n",
    "                                      cps3['drift'] / cps3['rep_rate'],\n",
    "                                      number_of_pulses_without_reference_to_samples) * np.exp(np.linspace(0,\n",
    "                                                                                                          100 * cps3['drift'],\n",
    "                                                                                                          number_of_pulses_without_reference_to_samples))\n",
    "  pulse_times_noise_black_box = np.random.normal(loc = np.arange(number_of_pulses_without_reference_to_samples) / cps3['rep_rate'],\n",
    "                                                 scale = cps3['jitter'] / cps3['rep_rate'],\n",
    "                                                 size = number_of_pulses_without_reference_to_samples)\n",
    "\n",
    "  # Synthesize to determine pulse time start points\n",
    "  actual_pulse_time_start_points = np.add(pulse_times_noise_black_box,\n",
    "                                          pulse_drift_black_box)\n",
    "\n",
    "  # Wherever sample points are coincident with pulse points, set those sample values to one\n",
    "  for actual_pulse_time_start_point in actual_pulse_time_start_points:\n",
    "    starting_sample = int(actual_pulse_time_start_point * cps3['sample_rate'])\n",
    "    if starting_sample + amount_of_samples_coincident_with_pulses < number_of_samples:\n",
    "      sample_set[starting_sample:starting_sample + amount_of_samples_coincident_with_pulses] = 1\n",
    "\n",
    "  # Add noise to all points of the sample train\n",
    "  sample_set += cps3['noise'] * np.random.normal(size = number_of_samples)\n",
    "\n",
    "  # Perform Fourier transform on the sample train to identify ampltidues of constituent frequencies\n",
    "  fourier_amplitudes = np.fft.fft(sample_set)\n",
    "\n",
    "  # Modify spectrum according to H parameter\n",
    "  h_parameter = calculate_h(cps3, comb_x_values_j)\n",
    "  final_amplitudes = fourier_amplitudes * h_parameter\n",
    "  return np.abs(final_amplitudes)\n",
    "\n",
    "def find_center(start_freq, first_harmon_width0):\n",
    "  center = start_freq + (0.5 * first_harmon_width0)\n",
    "  return center\n",
    "\n",
    "def trim_data(final_x_axis0, final_y_axis0, horizontal_comb_shift0, width0):\n",
    "  lower_bound_first_harmonic = horizontal_comb_shift0 - (0.5 * width0)\n",
    "  upper_bound_first_harmonic = horizontal_comb_shift0 + (0.5 * width0)\n",
    "\n",
    "  new_x_axis = []\n",
    "  new_y_axis = []\n",
    "\n",
    "  for individual in range(len(final_x_axis0)):\n",
    "    if final_x_axis0[individual] >= lower_bound_first_harmonic and final_x_axis0[individual] < upper_bound_first_harmonic:\n",
    "      new_x_axis.append(final_x_axis0[individual])\n",
    "      new_y_axis.append(final_y_axis0[individual])\n",
    "\n",
    "  grand_update = []\n",
    "  grand_update.append(new_x_axis)\n",
    "  grand_update.append(new_y_axis)\n",
    "  return grand_update\n"
   ],
   "id": "deeb9f140b89ce06",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T22:13:14.023289Z",
     "start_time": "2024-08-05T22:13:14.013474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''Misclustering Methods'''\n",
    "\n",
    "#CALL THIS\n",
    "def buildSpectralMisclusterRow(moleculeCount, chooseK, width, combCount, toothSpacing, IR_noise_exponent, combData):\n",
    "    true_labels = np.repeat(np.arange(moleculeCount), int(len(combData)/moleculeCount))\n",
    "    return[moleculeCount, chooseK, width, combCount, toothSpacing, IR_noise_exponent, run_spectral_clustering_and_evaluate(combData, true_labels, moleculeCount, n_runs=5)]\n",
    "\n",
    "#OR THIS\n",
    "def buildHDBSCANMisclusterRow(moleculeCount, chooseK, width, combCount, toothSpacing, IR_noise_exponent, combData):\n",
    "    true_labels = np.repeat(np.arange(moleculeCount), int(len(combData)/moleculeCount))\n",
    "    return[moleculeCount, chooseK, width, combCount, toothSpacing, IR_noise_exponent, run_hdbscan_and_evaluate(combData, true_labels, moleculeCount, n_runs=5)]\n",
    "\n",
    "def calculate_misclustered_percentage(labels, clusters):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of misclustered points.\n",
    "\n",
    "    Parameters:\n",
    "    labels: (m,)\n",
    "    clusters: (m,)\n",
    "\n",
    "    Returns:\n",
    "    misclustered_percentage: scalar\n",
    "    \"\"\"\n",
    "    misclustered_counts = []\n",
    "    unique_labels = np.unique(labels)\n",
    "    for label in unique_labels:\n",
    "        label_indices = labels == label\n",
    "        cluster_labels, counts = np.unique(clusters[label_indices], return_counts=True)\n",
    "        majority_count = np.max(counts)\n",
    "        misclustered_counts.append(np.sum(counts) - majority_count)\n",
    "    total_misclustered = np.sum(misclustered_counts)\n",
    "    total_points = len(labels)\n",
    "    misclustered_percentage = (total_misclustered / total_points) * 100\n",
    "    return misclustered_percentage\n",
    "\n",
    "# Runs spectral clustering multiple times and compute the average misclustered percentage\n",
    "def run_spectral_clustering_and_evaluate(X, labels, n_clusters, n_runs=5):\n",
    "    \"\"\"\n",
    "    Run spectral clustering multiple times and compute the average misclustered percentage.\n",
    "\n",
    "    Parameters:\n",
    "    X: (m, n)\n",
    "    labels: (m,)\n",
    "    n_clusters: scalar\n",
    "    n_runs: scalar\n",
    "\n",
    "    Returns:\n",
    "    mean_misclustered_percentage: scalar\n",
    "    \"\"\"\n",
    "    misclustered_percentages = []\n",
    "    for _ in range(n_runs):\n",
    "        sc = SpectralClustering(n_clusters=n_clusters, affinity='nearest_neighbors', assign_labels='kmeans')\n",
    "        predicted_labels = sc.fit_predict(X)\n",
    "        misclustered_percentage = calculate_misclustered_percentage(labels, predicted_labels)\n",
    "        misclustered_percentages.append(misclustered_percentage)\n",
    "    misclustered_percentages = sorted(misclustered_percentages)[1:-1]\n",
    "    return np.mean(misclustered_percentages)\n",
    "\n",
    "def run_hdbscan_and_evaluate(X, labels, n_clusters, n_runs=5):\n",
    "    misclustered_percentages = []\n",
    "    for _ in range(n_runs):\n",
    "        hdb = hdbscan.HDBSCAN(min_cluster_size=20)\n",
    "        predicted_labels = hdb.fit_predict(X)\n",
    "        misclustered_percentage = calculate_misclustered_percentage(labels, predicted_labels)\n",
    "        misclustered_percentages.append(misclustered_percentage)\n",
    "    misclustered_percentages = sorted(misclustered_percentages)[1:-1]\n",
    "    return np.mean(misclustered_percentages)\n"
   ],
   "id": "30730ba766a008df",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T22:13:57.735893Z",
     "start_time": "2024-08-05T22:13:14.024300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Testing on 5 molecules, widths: 10, 20, 30, 40, IR exponent: 1, 2, 3, 4, 5, 6, 7, Tooth Spacing: 1, 2, 5, 10, Comb counts: 1, 2, 3, 4, 5, 10, 15, 20\n",
    "MOLECULE_COUNT = 10\n",
    "IR_SPECTRA_FILE = np.load()[0:MOLECULE_COUNT+1] #No noise, from NIST\n",
    "WIDTHS = [10, 20, 30, 40]\n",
    "#COMB_COUNTS = [1, 2, 3, 4, 5, 10, 15, 20]\n",
    "COMB_COUNTS = [1, 2, 3]\n",
    "#IR_EXPONENTS = [1, 2, 3, 4, 5, 6, 7]\n",
    "IR_EXPONETS = [1, 2, 3]\n",
    "#TOOTH_SPACINGS = [1, 2, 5, 10]\n",
    "TOOTH_SPACINGS = [1, 5, 6, 8, 9, 10, 15, 20]\n",
    "misclusterArray = []\n",
    "warnings.filterwarnings('ignore')\n",
    "for exponent in IR_EXPONENTS:\n",
    "    noisy_IR_spectra = getNoisyIRSpectra(cleanIR=IR_SPECTRA_FILE, number_of_trials_per_molecule=10,max_speed_exponent=exponent)\n",
    "    print('Using exponent', str(exponent))\n",
    "    #for chooseK in range(2, MOLECULE_COUNT + 1):\n",
    "    for chooseK in [2, 3]:\n",
    "        variances = buildVarArray(combinedData=buildChooseKIRSpectraArrays(IR_SPECTRA_FILE, chooseK), molCount=MOLECULE_COUNT, k=chooseK)\n",
    "        print('Using choose', str(chooseK))\n",
    "        for width in WIDTHS:\n",
    "            print('Using width', str(width))\n",
    "            starts = wave_numbers_for_combination_variance(combination_array=variances, numCombs=np.max(COMB_COUNTS), combWidth=width)\n",
    "            for teeth_spacing in TOOTH_SPACINGS:\n",
    "                print('Using spacing', teeth_spacing)\n",
    "                for combCount in COMB_COUNTS:\n",
    "                    combInteraction = simulateCombInteraction(width=width, combCount=combCount, waveStarts=starts, teeth_spacing=teeth_spacing, noisy_IR_spectra=np.asarray(noisy_IR_spectra))\n",
    "                    misclusterArray.append(buildSpectralMisclusterRow(moleculeCount=MOLECULE_COUNT, chooseK=chooseK, width=width, combCount=combCount, toothSpacing=teeth_spacing, IR_noise_exponent=exponent, combData=combInteraction))\n",
    "                print('Done w/ spacing', str(teeth_spacing))\n",
    "            print('Done w/ width', str(width))\n",
    "        print('Done w/ choose', str(chooseK))\n",
    "    print('Done w/ exponent', str(exponent))\n",
    "                    \n",
    "np.save(, misclusterArray)"
   ],
   "id": "92bf1e0dc2fe87d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using exponent 1\n",
      "Using choose 2\n",
      "Using width 1\n",
      "Using spacing 1\n",
      "Iteration 1 of 17640\n",
      "Iteration 2 of 17640\n",
      "Iteration 3 of 17640\n",
      "Done w/ spacing 1\n",
      "Using spacing 2\n",
      "Iteration 4 of 17640\n",
      "Iteration 5 of 17640\n",
      "Iteration 6 of 17640\n",
      "Done w/ spacing 2\n",
      "Using spacing 3\n",
      "Iteration 7 of 17640\n",
      "Iteration 8 of 17640\n",
      "Iteration 9 of 17640\n",
      "Done w/ spacing 3\n",
      "Using spacing 4\n",
      "Iteration 10 of 17640\n",
      "Iteration 11 of 17640\n",
      "Iteration 12 of 17640\n",
      "Done w/ spacing 4\n",
      "Using spacing 5\n",
      "Iteration 13 of 17640\n",
      "Iteration 14 of 17640\n",
      "Iteration 15 of 17640\n",
      "Done w/ spacing 5\n",
      "Using spacing 6\n",
      "Iteration 16 of 17640\n",
      "Iteration 17 of 17640\n",
      "Iteration 18 of 17640\n",
      "Done w/ spacing 6\n",
      "Using spacing 7\n",
      "Iteration 19 of 17640\n",
      "Iteration 20 of 17640\n",
      "Iteration 21 of 17640\n",
      "Done w/ spacing 7\n",
      "Using spacing 8\n",
      "Iteration 22 of 17640\n",
      "Iteration 23 of 17640\n",
      "Iteration 24 of 17640\n",
      "Done w/ spacing 8\n",
      "Using spacing 9\n",
      "Iteration 25 of 17640\n",
      "Iteration 26 of 17640\n",
      "Iteration 27 of 17640\n",
      "Done w/ spacing 9\n",
      "Using spacing 10\n",
      "Iteration 28 of 17640\n",
      "Iteration 29 of 17640\n",
      "Iteration 30 of 17640\n",
      "Done w/ spacing 10\n",
      "Using spacing 11\n",
      "Iteration 31 of 17640\n",
      "Iteration 32 of 17640\n",
      "Iteration 33 of 17640\n",
      "Done w/ spacing 11\n",
      "Using spacing 12\n",
      "Iteration 34 of 17640\n",
      "Iteration 35 of 17640\n",
      "Iteration 36 of 17640\n",
      "Done w/ spacing 12\n",
      "Using spacing 13\n",
      "Iteration 37 of 17640\n",
      "Iteration 38 of 17640\n",
      "Iteration 39 of 17640\n",
      "Done w/ spacing 13\n",
      "Using spacing 14\n",
      "Iteration 40 of 17640\n",
      "Iteration 41 of 17640\n",
      "Iteration 42 of 17640\n",
      "Done w/ spacing 14\n",
      "Using spacing 15\n",
      "Iteration 43 of 17640\n",
      "Iteration 44 of 17640\n",
      "Iteration 45 of 17640\n",
      "Done w/ spacing 15\n",
      "Using spacing 16\n",
      "Iteration 46 of 17640\n",
      "Iteration 47 of 17640\n",
      "Iteration 48 of 17640\n",
      "Done w/ spacing 16\n",
      "Using spacing 17\n",
      "Iteration 49 of 17640\n",
      "Iteration 50 of 17640\n",
      "Iteration 51 of 17640\n",
      "Done w/ spacing 17\n",
      "Using spacing 18\n",
      "Iteration 52 of 17640\n",
      "Iteration 53 of 17640\n",
      "Iteration 54 of 17640\n",
      "Done w/ spacing 18\n",
      "Using spacing 19\n",
      "Iteration 55 of 17640\n",
      "Iteration 56 of 17640\n",
      "Iteration 57 of 17640\n",
      "Done w/ spacing 19\n",
      "Using spacing 20\n",
      "Iteration 58 of 17640\n",
      "Iteration 59 of 17640\n",
      "Iteration 60 of 17640\n",
      "Done w/ spacing 20\n",
      "Done w/ width 1\n",
      "Using width 5\n",
      "Using spacing 1\n",
      "Iteration 61 of 17640\n",
      "Iteration 62 of 17640\n",
      "Iteration 63 of 17640\n",
      "Done w/ spacing 1\n",
      "Using spacing 2\n",
      "Iteration 64 of 17640\n",
      "Iteration 65 of 17640\n",
      "Iteration 66 of 17640\n",
      "Done w/ spacing 2\n",
      "Using spacing 3\n",
      "Iteration 67 of 17640\n",
      "Iteration 68 of 17640\n",
      "Iteration 69 of 17640\n",
      "Done w/ spacing 3\n",
      "Using spacing 4\n",
      "Iteration 70 of 17640\n",
      "Iteration 71 of 17640\n",
      "Iteration 72 of 17640\n",
      "Done w/ spacing 4\n",
      "Using spacing 5\n",
      "Iteration 73 of 17640\n",
      "Iteration 74 of 17640\n",
      "Iteration 75 of 17640\n",
      "Done w/ spacing 5\n",
      "Using spacing 6\n",
      "Iteration 76 of 17640\n",
      "Iteration 77 of 17640\n",
      "Iteration 78 of 17640\n",
      "Done w/ spacing 6\n",
      "Using spacing 7\n",
      "Iteration 79 of 17640\n",
      "Iteration 80 of 17640\n",
      "Iteration 81 of 17640\n",
      "Done w/ spacing 7\n",
      "Using spacing 8\n",
      "Iteration 82 of 17640\n",
      "Iteration 83 of 17640\n",
      "Iteration 84 of 17640\n",
      "Done w/ spacing 8\n",
      "Using spacing 9\n",
      "Iteration 85 of 17640\n",
      "Iteration 86 of 17640\n",
      "Iteration 87 of 17640\n",
      "Done w/ spacing 9\n",
      "Using spacing 10\n",
      "Iteration 88 of 17640\n",
      "Iteration 89 of 17640\n",
      "Iteration 90 of 17640\n",
      "Done w/ spacing 10\n",
      "Using spacing 11\n",
      "Iteration 91 of 17640\n",
      "Iteration 92 of 17640\n",
      "Iteration 93 of 17640\n",
      "Done w/ spacing 11\n",
      "Using spacing 12\n",
      "Iteration 94 of 17640\n",
      "Iteration 95 of 17640\n",
      "Iteration 96 of 17640\n",
      "Done w/ spacing 12\n",
      "Using spacing 13\n",
      "Iteration 97 of 17640\n",
      "Iteration 98 of 17640\n",
      "Iteration 99 of 17640\n",
      "Done w/ spacing 13\n",
      "Using spacing 14\n",
      "Iteration 100 of 17640\n",
      "Iteration 101 of 17640\n",
      "Iteration 102 of 17640\n",
      "Done w/ spacing 14\n",
      "Using spacing 15\n",
      "Iteration 103 of 17640\n",
      "Iteration 104 of 17640\n",
      "Iteration 105 of 17640\n",
      "Done w/ spacing 15\n",
      "Using spacing 16\n",
      "Iteration 106 of 17640\n",
      "Iteration 107 of 17640\n",
      "Iteration 108 of 17640\n",
      "Done w/ spacing 16\n",
      "Using spacing 17\n",
      "Iteration 109 of 17640\n",
      "Iteration 110 of 17640\n",
      "Iteration 111 of 17640\n",
      "Done w/ spacing 17\n",
      "Using spacing 18\n",
      "Iteration 112 of 17640\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 27\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUsing spacing\u001B[39m\u001B[38;5;124m'\u001B[39m, teeth_spacing)\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m combCount \u001B[38;5;129;01min\u001B[39;00m COMB_COUNTS:\n\u001B[1;32m---> 27\u001B[0m     combInteraction \u001B[38;5;241m=\u001B[39m \u001B[43msimulateCombInteraction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwidth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwidth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcombCount\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcombCount\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwaveStarts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstarts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mteeth_spacing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mteeth_spacing\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnoisy_IR_spectra\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnoisy_IR_spectra\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     28\u001B[0m     misclusterArray\u001B[38;5;241m.\u001B[39mappend(buildSpectralMisclusterRow(moleculeCount\u001B[38;5;241m=\u001B[39mMOLECULE_COUNT, chooseK\u001B[38;5;241m=\u001B[39mchooseK, width\u001B[38;5;241m=\u001B[39mwidth, combCount\u001B[38;5;241m=\u001B[39mcombCount, toothSpacing\u001B[38;5;241m=\u001B[39mteeth_spacing, IR_noise_exponent\u001B[38;5;241m=\u001B[39mexponent, combData\u001B[38;5;241m=\u001B[39mcombInteraction))\n\u001B[0;32m     29\u001B[0m     iterator \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "Cell \u001B[1;32mIn[5], line 12\u001B[0m, in \u001B[0;36msimulateCombInteraction\u001B[1;34m(width, combCount, waveStarts, noisy_IR_spectra, drift_comb, jitter_comb, refractive_index_comb, absorption_coefficient_comb, total_experiment_duration, teeth_spacing)\u001B[0m\n\u001B[0;32m     10\u001B[0m input_ir_y_axis \u001B[38;5;241m=\u001B[39m noisy_IR_spectra[stance] \u001B[38;5;66;03m#These are the IR values to be multiplied against\u001B[39;00m\n\u001B[0;32m     11\u001B[0m transmittance_values \u001B[38;5;241m=\u001B[39m input_ir_y_axis \u001B[38;5;241m/\u001B[39m (np\u001B[38;5;241m.\u001B[39mmax(input_ir_y_axis)) \u001B[38;5;66;03m# Normalize\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m grand_y \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzeros\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mgrand_x\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m#This is the row that stores intensities\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m#after the interaction (i.e. it is what's saved)\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m#For Each Start Index/Each comb\u001B[39;00m\n\u001B[0;32m     15\u001B[0m rowToAdd \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(misclusterArray)",
   "id": "5ae39c629fb91801",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
